{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment with correct dependencies\n",
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LaTeXStrings\n",
    "using Revise\n",
    "using LinearAlgebra\n",
    "using DualNumbers\n",
    "using Random\n",
    "using Distributions\n",
    "\n",
    "\n",
    "pyplot()\n",
    "# Set default fonts for all plots\n",
    "#fnt = Plots.font(\"DejaVu Sans\", 8.0)\n",
    "#default(titlefont=fnt, guidefont=fnt, tickfont=fnt, legendfont=fnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need Golden Section Search\n",
    "include(\"files/code/gss.jl\")\n",
    "\n",
    "function gradient_descent_plot(f, gamma, xpos, ypos)\n",
    "    n = 100\n",
    "    x = range(-10.0,stop=10.0,length=n)\n",
    "    y = range(-10.0,stop=10.0,length=n)\n",
    "\n",
    "    xgrid = repeat(x',n,1)\n",
    "    ygrid = repeat(y,1,n)\n",
    "    z = zeros(n,n)\n",
    "\n",
    "    for i in 1:n\n",
    "        for j in 1:n\n",
    "            z[i:i,j:j] .= f([x[j];y[i]], gamma)\n",
    "        end\n",
    "    end\n",
    "    p = contour(xgrid, ygrid, z, colors=\"black\", linewidth=1.0, colorbar=false, aspect_ratio=1)\n",
    "    plot!(xpos, ypos, label=\"\")\n",
    "    scatter!(xpos, ypos, label=\"\")\n",
    "    return p\n",
    "end\n",
    "\n",
    "function gradient_descent_convergence_plot(xpos1, ypos1, xpos2, ypos2, labels)\n",
    "    p=plot()\n",
    "    n = length(xpos1)\n",
    "    steps = 1:n\n",
    "    dist = [sqrt(xpos1[i]^2+ypos1[i]^2) for i in steps]\n",
    "    p = plot(steps, dist, yscale=:log10, label=\"\", color=:blue, xlabel=\"# iterations\", ylabel=L\"\\left|\\mathbf{x}-\\mathbf{x}^* \\right|\")\n",
    "    scatter!(steps, dist, color=:blue, label=labels[1])\n",
    "    \n",
    "    n = length(xpos2)\n",
    "    steps = 1:n\n",
    "    dist = [sqrt(xpos2[i]^2+ypos2[i]^2) for i in steps]\n",
    "    plot!(steps, dist, yscale=:log10, label=\"\", color=:green)\n",
    "    scatter!(steps, dist, color=:green, label=labels[2])\n",
    "    \n",
    "    return p\n",
    "end\n",
    "\n",
    "function gradient_descent(f, df, gamma)\n",
    "    x0 = [10.0, 1.0]\n",
    "\n",
    "    g = df(x0, gamma)\n",
    "    n = 0 \n",
    "    x = x0\n",
    "    dx = - g / norm(g)\n",
    "\n",
    "    steps = Int[]\n",
    "    xposition = Float64[]\n",
    "    yposition = Float64[]\n",
    "\n",
    "    while n<20 && norm(g)>1E-5\n",
    "        append!(steps,n); append!(xposition, x[1]); append!(yposition, x[2]);\n",
    "        F(lambda) = f(x + lambda*dx, gamma)\n",
    "        lmin = gss.minimise(F, [-100.0, 100.0, 0.0], 1.0E-6)\n",
    "        x = x + lmin*dx\n",
    "        g = df(x, gamma)\n",
    "        dx = -g/norm(g)\n",
    "        n+=1\n",
    "    end\n",
    "    return xposition, yposition\n",
    "end\n",
    "\n",
    "function gradient_descent(f, df, gamma)\n",
    "    x0 = [10.0, 1.0]\n",
    "\n",
    "    g = df(x0, gamma)\n",
    "    n = 0 \n",
    "    x = x0\n",
    "    dx = - g / norm(g)\n",
    "\n",
    "    steps = Int[]\n",
    "    xposition = Float64[]\n",
    "    yposition = Float64[]\n",
    "\n",
    "    while n<20 && norm(g)>1E-5\n",
    "        append!(steps,n); append!(xposition, x[1]); append!(yposition, x[2]);\n",
    "        F(lambda) = f(x + lambda*dx, gamma)\n",
    "        lmin = gss.minimise(F, [-100.0, 0.0, 100.0], 1.0E-6)\n",
    "        x = x + lmin*dx\n",
    "        g = df(x, gamma)\n",
    "        dx = -g/norm(g)\n",
    "        n+=1\n",
    "    end\n",
    "    return xposition, yposition\n",
    "end\n",
    "\n",
    "function ADplot()\n",
    "    xgrid1 = range(-1.0,stop=1.0,length=101)\n",
    "    xgrid2 = range(-1.0,stop=1.0,length=51)\n",
    "    z = [Dual(x, 1.0) for x in xgrid2]\n",
    "    y = sin.(2*pi*xgrid1)\n",
    "    yprime = 2*pi*cos.(2*pi*xgrid1)\n",
    "    yz = sin.(2*pi*z)\n",
    "    p = plot(xgrid1, y, label=L\"y(x) = \\sin(2\\pi x)\", color=:red, ylims=(-7,16))\n",
    "    plot!(xgrid1, yprime, label=L\"y(x) = 2\\pi\\,\\cos(2\\pi x)\", color=:blue)\n",
    "    scatter!(xgrid2, realpart.(yz), label=\"Real[y(z)]\", color=:red)\n",
    "    scatter!(xgrid2, dualpart.(yz), label=\"Dual[y(z)]\", color=:blue)\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MA934\n",
    "\n",
    "## Nonlinear optimisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimisation in 1 dimension\n",
    "\n",
    "Given a function, $f(x)$ of a single variable, the task is to find a minimum of $f$. \n",
    "\n",
    "An ordered triple of points $(a,c,b)$ is said to *bracket* a minimum of $f$ if $f(c) < f(a)$ and $f(c) < f(b)$.\n",
    "\n",
    "Line search: evaluate  $f$  at a new point,  $x$, to construct a smaller bracketing triple. Iterate until a desired accuracy is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<img src=\"files/images/minf.png\" alt=\"array\" style=\"width: 400px;\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "Golden section search is a way to organise this search in an optimal way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden section search\n",
    "\n",
    "<img src=\"files/images/gss_intervals.png\" alt=\"array\" style=\"width: 800px;\"/> \n",
    "\n",
    "Most efficient to choose  $x$  in the larger of the two subintervals: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden section search:  : choosing new point, $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Case 1**: $[a, c]$ is the larger subinterval : new bracketing triple is either $(a,x,c)$  or $(x,c,b)$. Width of the new bracketing triple is independent of which outcome if :\n",
    "$$\n",
    "c - a = b - x.\n",
    "$$\n",
    "So we choose\n",
    "$$\n",
    "x = a + b - c.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Case 2**: if $[c,b]$ is the larger subinterval: new bracketing triple is either $(a,c,x)$ or $(c,x,b)$.  Width of the new bracketing triple is independent of which outcome if :\n",
    "$$\n",
    "x - a = b - c.\n",
    "$$\n",
    "So we again choose\n",
    "$$\n",
    "x = a + b -c.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden section search : choosing initial \"shape\"\n",
    "\n",
    "<img src=\"files/images/gss_intervals.png\" alt=\"array\" style=\"width: 400px;\"/> \n",
    "\n",
    "The idea is to choose $c$ such that the ratio of the width of the shorter subinterval to the width of the longer one remains constant between iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "Denote:\n",
    "\n",
    "* $p$: width of the longer subinterval in the old triple \n",
    "* $q$: width of the shorter subinterval in the old triple.\n",
    "* $r$ width of shorter subinterval in the *new* triple.\n",
    "\n",
    "There are several cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden section search : choosing initial \"shape\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "Case 1:\n",
    "\n",
    "> Case 1(A) : $\\frac{r}{p-r} = \\frac{q}{p}$\n",
    "> Case 1(B) : $\\frac{r}{q} = \\frac{q}{p}$\n",
    "\n",
    "Case 2: (get same equations) \n",
    "> Case 2(A) : $\\frac{r}{q} = \\frac{q}{p}$  \n",
    "> Case 2(B) : $\\frac{r}{p-r} = \\frac{q}{p}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<img src=\"files/images/gss_intervals.png\" alt=\"array\" style=\"width: 400px;\"/> \n",
    "\n",
    "Eliminating $r$ gives\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\left(\\frac{q}{p} \\right)^2 &+ \\left(\\frac{q}{p} \\right) - 1 = 0 \\\\ \n",
    "\\Rightarrow \\left(\\frac{q}{p} \\right) &= \\frac{\\sqrt{5}\\pm 1}{2}.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden section search\n",
    "\n",
    "We choose the - sign since we assumed $\\frac{q}{p}<1$ ($\\frac{q}{p} = \\phi$, 1/golden ratio). \n",
    "\n",
    "Since $x$ is already determined, $x=a+b−c$, if we start with the correct ratio,  $\\frac{q}{p}$ , this will be preserved when as we iterate.\n",
    "\n",
    "Convergence is exponential in the number of iterations: width of interval after $n$ iterations is $(b-a)\\,\\phi^n$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden section search: convergence\n",
    "\n",
    "Finding the minimum of  $f(x)=x^2$  at  $x=0$:\n",
    "\n",
    "<img src=\"files/images/gss_convergence.png\" alt=\"array\" style=\"width: 800px;\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Golden section search : implementation\n",
    "\n",
    "Implementation is simplified using temporary variables $x_1$ and $x_2$ to store the points $x$ and $c$ (in Case 1) or $c$ and $x$ (in Case 2) and $f_1$ and $f_2$ to store the associated function values. \n",
    "\n",
    "Regardless of the order in which previous points were evaluated, the new triple will centre on the point with the smallest value of $f$ found so far. Thus by comparing $f_1$ to $f_2$, there are only two cases:\n",
    "\n",
    "\n",
    "<img src=\"files/images/gss_implementation.png\" alt=\"array\" style=\"width: 400px;\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimisation in $\\mathbb{R^n}$ : line minimisation\n",
    "\n",
    "Given a function, $f: \\mathbb{R}^n \\to \\mathbb{R}$, a position vector, $\\mathbf{x} \\in \\mathbb{R}^n$, and a direction vector, $\\mathbf{v} \\in \\mathbb{R}^n$, the *line minimiser* of $f$ from $\\mathbf{x}$ in the direction $\\mathbf{v}$ is the point \n",
    "$$\n",
    "\\mathbf{x}^* = \\mathbf{x} + \\lambda^*\\,\\mathbf{v}\n",
    "$$ \n",
    "where\n",
    "$$\n",
    "\\lambda^* = \\arg \\min_\\lambda f(\\mathbf{x} + \\lambda\\,\\mathbf{v}).\n",
    "$$\n",
    "Note that although  $f$ is a function of $n$ variables, this minimisation with respect to $\\lambda$ is one dimensional and can be done, for example, using Golden Section Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimisation in $\\mathbb{R^n}$ : gradient descent\n",
    "\n",
    "Gradient descent is one a family of unconstrained optimisation algorithms that can be used when the gradient of the objective function is known or computable.\n",
    "\n",
    "* Given $f : \\mathbb{R}^n \\to \\mathbb{R}$ and any point, $\\mathbf{x} \\in \\mathbb{R}^n$, $-\\nabla f(\\mathbf{x})$ points in the direction of steepest decrease of $f$ at $\\mathbf{x}$.\n",
    "* Idea is to keep going \"downhill\" until a minimum is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent algorithm\n",
    "\n",
    "Start from a point, $\\mathbf{x}_0$.\n",
    "\n",
    "1. Calculate the unit direction vector \n",
    "$$\\mathbf{v}_n = - \\frac{\\nabla\\,f(\\mathbf{x}_n)}{\\left| \\nabla\\,f(\\mathbf{x}_n)\\right|}.$$\n",
    "2. Perform line minimisation in direction of $\\mathbf{v}_n$:\n",
    "$$\n",
    "\\lambda^* = \\arg \\min_\\lambda f(\\mathbf{x}_n + \\lambda\\,\\mathbf{v}_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "3. Move to new position $\\mathbf{x}_{n+1} = \\mathbf{x}_n + \\lambda^*\\,\\mathbf{v}_n$. \n",
    "4. Repeat until $\\left| \\nabla\\,f(\\mathbf{x}_n) \\right| < \\epsilon_\\text{tol}$.\n",
    "\n",
    "Normalisation of $\\mathbf{v}_n$ is not strictly necessary but helps keep accuracy as minimum is approached.\n",
    "\n",
    "Note: any descent directions will work - gradient is the most efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent: example in $\\mathbb{R}^2$\n",
    "\n",
    "Consider the function\n",
    "$$\n",
    "f(x, y) = \\frac{1}{2}\\left(x^2 + \\gamma y^2 \\right).\n",
    "$$\n",
    "The parameter $\\gamma>0$ controls the ellipticity.\n",
    "The gradient is\n",
    "$$\n",
    "\\nabla\\,f(x,y) = (x, \\gamma\\,y)^T.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "# Parameter to control ellipticity of the bowl\n",
    "gamma = 10.0\n",
    "# Define quadratic function of two variables \n",
    "f(x, gam) = 0.5*(x[1]^2.0 + gam*x[2]^2.0)\n",
    "# Define corresponding gradient\n",
    "df(x, gam) = [x[1], gam*x[2]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent: example in $\\mathbb{R}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gamma=4.0\n",
    "xpos1, ypos1 = gradient_descent(f, df, gamma)\n",
    "gradient_descent_plot(f, gamma, xpos1, ypos1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "gamma=10.0\n",
    "xpos2, ypos2 = gradient_descent(f, df, gamma)\n",
    "gradient_descent_plot(f, gamma, xpos2, ypos2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent: Why the zig zags? \n",
    "\n",
    "\n",
    "Remember that $\\mathbf{x}_{n+1}$ is a line minimiser of $f$ from $\\mathbf{x}_n$ in the direction of $\\mathbf{v}_n$. \n",
    "\n",
    "Letting $g(\\lambda) = f(\\mathbf{x}_n + \\lambda\\,\\mathbf{v}_n)$, we must have\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{d\\,f}{d\\,\\lambda}(\\lambda^*) &= 0\\\\\n",
    "\\Rightarrow \\sum_{i=1}^n \\frac{\\partial\\,f}{\\partial\\,x_i}(\\mathbf{x}_n+\\lambda^*\\mathbf{v}_n) \\,v_{n\\,i} &=0\\\\\n",
    "\\Rightarrow \\nabla\\,f(\\mathbf{x}_{n+1}) \\cdot \\mathbf{v}_n &= 0.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Each step of the gradient descent algorithm is perpendicular to the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent: convergence\n",
    "\n",
    "* convergence is exponential but depends on $\\gamma$.\n",
    "* larger $\\gamma$ is harder - narrower valley requires more zig zags.\n",
    "* this latter feature means vanilla gradient descent is rarely used in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "gradient_descent_convergence_plot(xpos1, ypos1, xpos2, ypos2, [L\"\\gamma=4\", L\"\\gamma=15\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numerical calculation of derivatives\n",
    "\n",
    "Explicit calculation of $\\nabla\\,f(\\mathbf{x})$ is sometimes inconvenient. In such cases it is helpful to be able to calculate derivatives numerically. Several approaches:\n",
    "\n",
    "* Finite difference approximation: the workhorse.\n",
    "* Automatic differentiation: uses dual numbers\n",
    "* Spectral methods: uses Fourier transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dual Numbers: basic arithmetic\n",
    "\n",
    "Dual numbers are of the form $z = x + \\varepsilon\\, y$ with $x$, $y \\in \\mathbb{R}$ and $\\varepsilon^2 = 0$.\n",
    "\n",
    "Addition rule:\n",
    "$$\n",
    "\\begin{align*}\n",
    "z_1 + z_2 & = (x_1 + \\varepsilon\\,y_1) +  (x_2 + \\varepsilon\\,y_2)\\\\\n",
    " & =  (x_1 + x_2) + \\varepsilon\\,(y_1+y_2).\n",
    " \\end{align*}\n",
    " $$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "Multiplication rule:\n",
    "$$\n",
    " \\begin{align*}\n",
    "z_1 * z_2 & = (x_1 + \\varepsilon\\,y_1) *  (x_2 + \\varepsilon\\,y_2) \\\\\n",
    "& =  (x_1 x_2) + \\varepsilon\\,(x_1\\,y_2+x_2\\, y_1).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Dual conjugate:\n",
    "$$\n",
    "\\bar{z} = x - \\varepsilon\\, y.\n",
    "$$\n",
    "\n",
    "As with the complex numbers, $z\\,\\bar{z}$ is purely real:\n",
    "$$\n",
    "z\\,\\bar{z} = (x + \\varepsilon\\,y) * (x - \\varepsilon\\,y)  = x^2.  \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dual numbers: division and powers\n",
    "\n",
    "Division is defined using the conjugate:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{z_1}{z_2} &= \\frac{z_1\\,\\bar{z}_2}{z_2 \\bar{z}_2}\\\\\n",
    "&= \\frac{(x_1 + \\varepsilon\\,y_1) (x_2 - \\varepsilon\\,y_2) }{x_2^2}\\\\\n",
    "&= \\frac{x_1\\,x_2 + \\varepsilon\\,(y_1\\,x_2 - x_1\\,y_2)}{x_2^2}\\\\\n",
    "&= \\frac{x_1}{x_2} + \\varepsilon\\,\\left( \\frac{y_1\\,x_2 - x_1\\,y_2}{x_2^2}\\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "Division is not defined for $\\text{Re}(z_2) = 0$ so, unlike $\\mathbb{C}$, the dual numbers do not form a field.\n",
    "\n",
    "Powers are obtained using the binomial theorem:\n",
    "\\begin{align}\n",
    "\\nonumber (x+ \\varepsilon\\, y)^n & = \\sum_{k=0}^n \\binom{n}{k}\\,x^{n-k}\\, (\\varepsilon\\, y)^k\\\\\n",
    "\\nonumber &= \\binom{n}{0} x^n + \\binom{n}{1}\\,x^{n-1}\\,\\varepsilon\\, y\\\\\n",
    "\\label{eq-ADpower} & = x^n + \\varepsilon\\, y\\, n\\,x^{n-1}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dual numbers: automatic differentiation\n",
    "\n",
    "Notice that for $f(x) = x^n$,\n",
    "\n",
    "$$\n",
    "f(x+\\varepsilon\\,y) = f(x) + \\varepsilon\\,y\\, f^\\prime(x).\n",
    "$$\n",
    "\n",
    "Evaluating $f(x) = x^n$ at $x + \\varepsilon$ gives the derivative of $f(x)$ as the dual component.\n",
    "\n",
    "This is called *automatic differentiation*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "This property trivially extends to polynomial functions and *formally* extends to real analytic functions via their Taylor series:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&f(x + \\varepsilon\\,y) = \\sum_{k=0}^\\infty \\frac{1}{k!}\\,f^{(k)}(x)\\, \\varepsilon^k\\,y^k\\\\\n",
    "& =  f(x) + \\varepsilon\\,y\\, f^\\prime(x).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Also the chain rule works (check). If  $h(x) = f(g(x))$:\n",
    "\n",
    "$$\n",
    "h(x + \\varepsilon) = f(g(x)) + \\varepsilon\\,f^\\prime(g(x))\\,g^\\prime(x).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dual numbers in Julia\n",
    "\n",
    "Advantages of automatic differentiation:\n",
    "* no need to work out complicated analytic formulae for derivatives\n",
    "* $\\text{Dual}[z]$ correct to the same precision as $\\text{Real}[z]$.\n",
    "\n",
    "Dual arithmetic is supported in Julia by various packages, the most basic of which is DualNumbers.jl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "using DualNumbers\n",
    "z1 = Dual(2.0,3.0)\n",
    "z2 = Dual(1.0, 2.0)\n",
    "z1*z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "x = range(-1.0,stop=1.0,length=101)\n",
    "z = [Dual(a, 1.0) for a in x]\n",
    "y = sin.(2*pi*x)\n",
    "ADplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Automatic differentiation for multivariate functions\n",
    "\n",
    "In the formulation presented above, automatic differentiation of multivariate functions requires a separate function evaluation for each partial derivative.\n",
    "\n",
    "For a multivariate function $f : \\mathbb{R}^n \\to \\mathbb{R}$, to calculate the partial derivative with respect to $x_i$, we have to add $\\varepsilon$ to the $i^\\text{th}$ component of the argument and then take the dual part.\n",
    "For example, in $\\mathbb{R}^2$ we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x + \\varepsilon, y) &= f(x,y) + \\varepsilon\\,\\frac{\\partial f}{\\partial x} (x,y)\\\\\n",
    "f(x, y + \\varepsilon) &= f(x,y) + \\varepsilon\\,\\frac{\\partial f}{\\partial y} (x,y).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Minimisation of sums\n",
    "\n",
    "Problems in statistical inference, ML and data science frequently produce optimisation problems that involve minimising a sum:\n",
    "$$\n",
    "\\min_\\beta f(\\beta) = \\min_\\beta \\frac{1}{n}\\sum_{i=1}^n L(\\beta, \\mathbf{x}_i).\n",
    "$$\n",
    "Often $\\beta$ represents some model parameters, $\\mathbf{x}_i$ represents the $i^\\text{th}$ observation in the training data set and $L$ is a loss function of some kind.\n",
    "\n",
    "Can be solved with GD by calculating the gradient with respect to $\\beta$:\n",
    "$$\n",
    "(\\nabla f(\\beta))_j = \\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial\\, L}{\\partial\\, \\beta_j}(\\beta, \\mathbf{x}_i)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "If the training data is large ($n \\gg 1$), then calculating the gradient can become very expensive.  Stochastic Gradient Descent addresses this issue.\n",
    "\n",
    "Idea is to estimate the gradients as:\n",
    "\n",
    "$$\n",
    "(\\nabla f(\\beta))_j \\approx (\\tilde{\\nabla} f(\\beta))_j = \\frac{\\partial\\, L}{\\partial\\, \\beta_j}(\\beta, \\mathbf{\\tilde{x}}_{i})\n",
    "$$\n",
    "\n",
    "where $\\tilde{\\mathbf{x}}_i$ is the $i^\\text{th}$ training data point from the training data set having first undergone a random shuffle.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stochastic Gradient Descent : learning rate\n",
    "\n",
    "With SGD, we typically do not perform full line minimisations (due to sampling noise). Instead the basic update rule is\n",
    "$$\n",
    "\\mathbf{\\beta}_{n+1} = \\mathbf{\\beta}_n - \\zeta_n\\,(\\tilde{\\nabla} f(\\beta_n)). \n",
    "$$\n",
    "$\\zeta_n$ is a (decreasing) function of $n$ often called the *learrning rate*. For example,\n",
    "\n",
    "$$\n",
    "\\zeta_n = \\frac{\\zeta_0}{1+\\zeta_1\\,n}\n",
    "$$\n",
    "\n",
    "$\\zeta_0$ and $\\zeta_1$ are *hyperparameters*. Note that $\\sum_{n=1}^\\infty \\zeta_n$ is a divergent series. Prevents SGD from stalling.\n",
    "\n",
    "Due to sampling noise, SGD only converges to a \"noise ball\" around the minimum of $f(\\beta)$ rather than to the true minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"files/code/figures.jl\")\n",
    "pyplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Logistic regression\n",
    "\n",
    "Binary variable, $Y \\in \\left\\{0, 1\\right\\}$, explanatory variable, $X \\in \\mathbb{R}$. \n",
    "\n",
    "Example: how is going crazy ($Y$) related to the number of hours per week ($X$) spent on MS Teams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figures.plot_logistic_regression_data([0.0, 40.0] , [-19.0, 1.0], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume $Y = \\left\\{Y_i, i=1\\ldots n \\right\\}$ are id Bernoulli with parameters, $p_i$, depending on $X = \\left\\{X_i, i=1\\ldots n \\right\\}$:\n",
    "$$\n",
    "\\mathbb{P}(Y | X) = \\prod_{i=1}^n p(X_i)^{Y_i} \\, (1 -p(X_i))^{1-Y_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Logistic regression\n",
    "\n",
    "How should Bernoulli parameter, $p$, vary with $X$?  \n",
    "Assume *log odds* are a linear function of $X$:\n",
    "$$\n",
    "\\log\\left(\\frac{p(X)}{1-p(X)} \\right) = \\beta_0 + \\beta_1\\,X = \\beta \\cdot \\mathbf{X}\n",
    "$$\n",
    "where $\\mathbf{X} = \\left(1, X\\right)$ and $\\beta = \\left(\\beta_0, \\beta_1\\right)$.\n",
    "\n",
    "Solve for $p(X)$:\n",
    "$$\n",
    "p(X) = \\sigma(\\beta\\cdot\\mathbf{X}),\n",
    "$$\n",
    "where $\\sigma(x)$ is the sigmoid function:\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+\\exp(-x)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Logistic regression as an optimisation problem\n",
    "\n",
    "Obviously cannot use least squares to select optimal values of $\\beta$. \n",
    "\n",
    "Instead maximise, $\\mathbb{P}(Y | X) $ - *likelihood of $Y$ given $X$* - with respect to $\\beta$. \n",
    "\n",
    "In fact easier to minimise $-\\log \\mathbb{P}(Y | X)$ because it turns task into a sum minimisation: \n",
    "\n",
    "$$\n",
    "\\beta_* = \\arg \\min_{\\beta} \\sum_{i=1}^n -Y_i\\,\\log(\\sigma(\\beta\\cdot\\mathbf{X}_i)) - (1 -Y_i)\\,\\log(1-\\sigma(\\beta\\cdot\\mathbf{X}_i)).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Logistic regression via gradient descent\n",
    "\n",
    "We can solve this sum minimisation problem with GD or SGD. First we need the gradient of the objective function,\n",
    "$$\n",
    "L(\\beta) = \\sum_{i=1}^n -Y_i\\,\\log(\\sigma(\\beta\\cdot\\mathbf{X}_i)) - (1 -Y_i)\\,\\log(1-\\sigma(\\beta\\cdot\\mathbf{X}_i)).\n",
    "$$\n",
    "Direct calculation gives (check)\n",
    "$$\n",
    "(\\nabla L (\\beta))_k = \\sum_{i=1}^n (\\sigma(\\beta\\cdot\\mathbf{X}_i)) - Y_i)\\,(\\mathbf{X}_i)_k\n",
    "$$\n",
    "where $k\\in\\left\\{0,1\\right\\}$ and $(\\mathbf{X}_i)_k$ is the k$^\\text{th}$ component of $\\mathbf{X}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation: generate some test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n = 1000 # Number of data points\n",
    "xrange = [-20.0, 20.0] # Range of values for x\n",
    "β0 = [1.0, 1.0] # True parameter values\n",
    "\n",
    "sigmoid(x) = 1.0/(1.0+exp(-x))\n",
    "\n",
    "# Generate some data\n",
    "Random.seed!(2)\n",
    "X = zeros(n,2)\n",
    "X[:,1] .= 1.0\n",
    "X[:,2] = rand(Uniform(xrange[1], xrange[2]), n)\n",
    "Y = [rand(Bernoulli(sigmoid(β0⋅X[i,:]))) for i in 1:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation: define the objective function\n",
    "\n",
    "Need negative log likelihood of the data $(\\mathbf{X}, \\mathbf{Y})$ for a given value of $\\beta$.  \n",
    "First calculate the components of the sum as separate lists and then assemble them at end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "function L(β)\n",
    "    S = [ sigmoid(β⋅X[i,:]) for i in 1:n]\n",
    "    # It *can* happen that S[i]==0.0 or 1.0 due to finite precision. This needs to \n",
    "    # be handled separately to avoid log(0). Use the ? :  ternary operator\n",
    "    A1 = [S[i] == 0.0 ? 0.0 : Y[i]*log(S[i]) for i in 1:n]\n",
    "    A2 = [S[i] == 1.0 ? 0.0 : (1-Y[i])*log(1.0-S[i]) for i in 1:n]\n",
    "    A = [A1[i] + A2[i] for i in 1:n]\n",
    "    return -1.0*sum(A)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot of L(β)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p = figures.contour_plot(L, [-5.0,5.0], [0.5, 10.0])\n",
    "scatter!([β0[1]],[β0[2]], marker=:x, markersize=8, label=\"β0\",  color=:red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation: define the gradient of the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Define the gradient of the likelihood function with respect to β\n",
    "function dL(β)\n",
    "    S = [ sigmoid(β⋅X[i,:]) for i in 1:n]\n",
    "    A1 = [(S[i] - Y[i])*X[i,1] for i in 1:n]\n",
    "    A2 = [(S[i] - Y[i])*X[i,2] for i in 1:n]\n",
    "    return [sum(A1), sum(A2)]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementation: define the partial gradient (for SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ith partial gradient of the likelihood function with respect to β\n",
    "function dL(β,i)\n",
    "    S = sigmoid(β⋅X[i,:])\n",
    "    A1 = (S - Y[i])*X[i,1]\n",
    "    A2 = (S - Y[i])*X[i,2]\n",
    "    return [A1, A2]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run gradient descent\n",
    "\n",
    "This time we will use a pre-defined step size, $\\eta_1(k)$, rather than doing full line minimisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"files/code/GD.jl\")\n",
    "η1(k) = 1.0/(1.0 + k/2.0)\n",
    "xpos, ypos = GD.gradient_descent(L, dL, [-5.0, 0.0], 1.0E-6, 200, η1)\n",
    "println(\"GD: β = (\", xpos[end], \", \", ypos[end],\").\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "η2(k) = 1.0/(1.0 + k/50.0)\n",
    "xpos2, ypos2 = GD.stochastic_gradient_descent(L, dL, [-5.0, 0.0], 500, η2, n, 1)\n",
    "println(\"SGD: β = (\", xpos2[end], \", \", ypos2[end],\").\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparison of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "p = figures.contour_plot(L, [-5.0,5.0], [0.25, 10.0])\n",
    "plot!(xpos, ypos, label=\"Gradient descent\", linewidth=3, color=:blue)\n",
    "plot!(xpos2, ypos2, label=\"Stochastic Gradient Descent\", marker=:circle, color=:green)\n",
    "scatter!([β0[1]],[β0[2]], marker=:x, markersize=8, label=\"β0\",  color=:red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constrained nonlinear optimisation\n",
    "\n",
    "Given $f(\\mathbf{x}) : \\mathbb{R}^n \\to \\mathbb{R}$, we can combine what we have learned about gradient descent with what we have learned about linear programming to solve constrained nonlinear optimisation problems of the form:\n",
    "$$\n",
    "\\min_{\\mathbf{x}\\in C} f(\\mathbf{x}), \n",
    "$$\n",
    "where $C \\subset \\mathbb{R}^n$ is defined by a set of linear inequalities.\n",
    "\n",
    "Clearly GD alone is insufficient since $\\mathbf{x}_n$ could leave the feasible set, $C$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constrained nonlinear optimisation: Frank-Wolfe algorithm\n",
    "\n",
    "Idea is to linearise $f(\\mathbf{x})$ about $\\mathbf{x}_n$ at each iteration of GD and solve the associated LP to obtain an $\\mathbf{x}_{n+1}$, which cannot leave $C$ by construction.\n",
    "\n",
    "Given current point, $\\mathbf{x}_n$, \n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = f(\\mathbf{x}_n)+(\\mathbf{x}-\\mathbf{x}_n) \\cdot \\nabla\\,f(\\mathbf{x}_n) + \\mathcal{O}(\\left| \\mathbf{x}-\\mathbf{x}_n \\right|^2).\n",
    "$$\n",
    "\n",
    "Neglecting the $\\mathcal{O}(\\left| \\mathbf{x}-\\mathbf{x}_n \\right|^2)$ terms, minimisation of $f(\\mathbf{x})$, is now a LP:\n",
    "\n",
    "$$\n",
    "x^* = \\arg \\min_{\\mathbf{x}\\in C}\\ \\left[ \\mathbf{x} \\cdot \\nabla\\,f(\\mathbf{x}_n)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constrained nonlinear optimisation: Frank-Wolfe algorithm\n",
    "\n",
    "Start from a point, $\\mathbf{x}_0 \\in C$. At each iteration, $n$:\n",
    "\n",
    "1. Solve the linearised problem\n",
    "$$\n",
    "x^* = \\arg \\min_{\\mathbf{x}\\in C}\\ \\left[\\mathbf{x} \\cdot \\nabla\\,f(\\mathbf{x}_n)\\right]\n",
    "$$\n",
    "2. Perform *bounded* line minimisation of $f(\\mathbf{x})$ from $\\mathbf{x}_n$ in the direction of $\\mathbf{x}^*-\\mathbf{x}_n$: \n",
    "$$\n",
    "\\lambda^* = \\arg \\min_{\\lambda \\in \\left[0,1\\right]} f \\left( \\mathbf{x}_n + \\lambda\\,(\\mathbf{x}^*-\\mathbf{x}_n)\\right)\n",
    "$$\n",
    "3. Update\n",
    "$$\n",
    "\\mathbf{x}_{n+1} = \\mathbf{x}_n + \\lambda^* \\,(\\mathbf{x}^*-\\mathbf{x}_n).\n",
    "$$\n",
    "4. Repeat until desired tolerance is reached."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
